{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b069048-25d2-45a8-b43e-a0a9f5f62b92",
   "metadata": {},
   "source": [
    "# OpenAI video testing\n",
    "\n",
    "Conda env: gptwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a4ca3-f4dd-435a-844b-212d282dc10d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224e92b0-5cb5-45b9-a062-de4bc307675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, Audio\n",
    "\n",
    "import cv2  # We're using OpenCV to read video, to install !pip install opencv-python\n",
    "import base64\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5fe390-b96d-4ed5-8c50-467d7efed2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"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\",\n",
    "                                       \"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\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2378061-0419-4f0e-b1c7-f58700b2a748",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c74e11-ba42-4c99-b7af-70604fce7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(video_path, verbose = True):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    base64Frames = []\n",
    "    while video.isOpened():\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "    \n",
    "    video.release()\n",
    "    if (verbose):\n",
    "        print(len(base64Frames), \"frames read.\")\n",
    "\n",
    "    return base64Frames\n",
    "\n",
    "def query_video(frames, prompt, frame_sample = 100, resize_pixels = 768, max_tokens = 200, model = \"gpt-4-turbo\",\n",
    "                temperature = 0,\n",
    "                verbose = True):\n",
    "    messages = [\n",
    "        { # Prompt\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "        { # Context in the form of image frames sampled from the video.\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                *map(lambda x: {\"image\": x, \"resize\": resize_pixels}, frames[0::frame_sample]),\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "    \n",
    "    result = client.chat.completions.create(**params)\n",
    "    if verbose:\n",
    "        print(result.choices[0].message.content)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cfa703-05b6-40ba-8258-8802ebc5c968",
   "metadata": {},
   "source": [
    "## Prompt tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1be153-3402-401c-ad51-9a598a22016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238 frames read.\n"
     ]
    }
   ],
   "source": [
    "# Load a video\n",
    "frames = load_video(\"videos/vaping_modeling.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e481b3-714b-46e3-bb10-0495fe3977a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Man vaping outdoors - High probability of vaping\n",
      "2. Man looking serious - No visible vaping\n",
      "3. Man standing confidently - No visible vaping\n"
     ]
    }
   ],
   "source": [
    "# Run an Open API GPT query.\n",
    "query_video(frames,\n",
    "            (\"These are frames from a video that I want to upload. Describe what is in this video. \"+\n",
    "            \"Please also provide the probability that there is vaping in each frame. Limit the description to three words per frame\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c1a21c2-a8e8-4ba2-baa7-f3d159200bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Man holding decorative mouthpiece. Probability of vaping: 0%.\n",
      "2. Man looking away, no vaping. Probability of vaping: 0%.\n",
      "3. Man standing outdoors, no vaping. Probability of vaping: 0%.\n"
     ]
    }
   ],
   "source": [
    "# Run an Open API GPT query.\n",
    "query_video(frames,\n",
    "            (\"You are an expert in tobacco, e-cigarette, and vaping marketing. These are frames from a video for you to carefully evaluate. \" +\n",
    "             \"Describe what is in this video using no more than 5 words per frame. \"\n",
    "             \"In particular, note any products that are e-cigarettes, tobacco, mods, pods, e-juices, vaping, e-juice containers, or similar. \" +\n",
    "             \"Also provide an accurate numeric probability in brackets that there is vaping in each frame. For example: Probability of vaping: 5%. \"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4f9b7-1b42-4bf8-9aa7-591997516bf0",
   "metadata": {},
   "source": [
    "## Run on directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100f1916-bcc4-43e9-b16b-328193ce113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 videos to analyze\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "video_dir = Path(\"videos/GPT4_themes\")\n",
    "videos = list(video_dir.glob('**/*.mp4'))\n",
    "print(\"Found\", len(videos), \"videos to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de8d76ba-a504-415e-961f-abb207040c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('videos/GPT4_themes/fashion/fabio_fashion_3.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/chamillioneyes_fashion_1.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_2.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_18.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_19.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_14.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_4.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_17.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_8.mp4'),\n",
       " PosixPath('videos/GPT4_themes/fashion/fabio_fashion_9.mp4')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa773c03-9c1c-4b17-ba25-6b141e022b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These are frames from a video that I want to upload. Describe what is in this video. Also describe if there is nicotine vaping in this video. Also describe if there is cannabis vaping in this video. Also describe if there is fashion  in this video. Also describe if there is entertainment (for example, dj, videogames)  in this video. Also describe if there is technology in this video (do not include vaping). Also describe if there is active lifestyle (for example sport) in this video. Limit the description to yes or no responses for each category. Also identify if the person in this video is between the age of 0-11 or 12-17 or 18-21or 22-25 or 26-30 or 31-40 or 41-50 or 51-60 or older than 60 years old. Format the results by surrounding each answer with dollar signs, like $Yes$ or $No$.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_noprobs = (\"These are frames from a video that I want to upload. Describe what is in this video. \"+\n",
    "            \"Also describe if there is nicotine vaping in this video. \"+\n",
    "            \"Also describe if there is cannabis vaping in this video. \"+\n",
    "            \"Also describe if there is fashion  in this video. \"+\n",
    "            \"Also describe if there is entertainment (for example, dj, videogames)  in this video. \"+\n",
    "            \"Also describe if there is technology in this video (do not include vaping). \"+\n",
    "            \"Also describe if there is active lifestyle (for example sport) in this video. \"+\n",
    "            \"Limit the description to yes or no responses for each category. \" + \n",
    "            \"Also identify if the person in this video is between the age of 0-11 or 12-17 or 18-21\"+ \n",
    "            \"or 22-25 or 26-30 or 31-40 or 41-50 or 51-60 or older than 60 years old. \" +\n",
    "            \"Format the results by surrounding each answer with dollar signs, like $Yes$ or $No$.\")\n",
    "prompt_noprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1485ddc8-86ba-4a02-85df-7f20be5a9c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These are frames from a video that I want to upload. Describe what is in this video. Also provide the probability that there is nicotine vaping in this video. Also provide the probability that there is cannabis vaping in this video. Also provide the probability that there is fashion  in this video. Also provide the probability that there is entertainment (for example, dj, videogames)  in this video. Also provide the probability that there is technology in this video (do not include vaping). Also provide the probability that there is active lifestyle (for example sport) in this video. Limit the description to numeric probability responses for each category, like 100% or 10%. Also provide the probability that the person in this video is between the age of 0-11 or 12-17 or 18-21or 22-25 or 26-30 or 31-40 or 41-50 or 51-60 or older than 60 years old. Format the results by surrounding each answer with dollar signs, like $75%$ or $25%$.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_probs = (\"These are frames from a video that I want to upload. Describe what is in this video. \"+\n",
    "            \"Also provide the probability that there is nicotine vaping in this video. \"+\n",
    "            \"Also provide the probability that there is cannabis vaping in this video. \"+\n",
    "            \"Also provide the probability that there is fashion  in this video. \"+\n",
    "            \"Also provide the probability that there is entertainment (for example, dj, videogames)  in this video. \"+\n",
    "            \"Also provide the probability that there is technology in this video (do not include vaping). \"+\n",
    "            \"Also provide the probability that there is active lifestyle (for example sport) in this video. \"+\n",
    "            \"Limit the description to numeric probability responses for each category, like 100% or 10%. \" + \n",
    "            \"Also provide the probability that the person in this video is between the age of 0-11 or 12-17 or 18-21\"+ \n",
    "            \"or 22-25 or 26-30 or 31-40 or 41-50 or 51-60 or older than 60 years old. \" +\n",
    "            \"Format the results by surrounding each answer with dollar signs, like $75%$ or $25%$.\")\n",
    "prompt_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "520ab79c-7288-4189-ad7e-82d41544f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_videos(videos, prompt, verbose = False):\n",
    "    results = {}\n",
    "    for video in videos:\n",
    "        video_name = video.stem\n",
    "        if (verbose):\n",
    "            print(f\"\\nAnalyzing {video_name}\")\n",
    "        # Import video\n",
    "        frames = load_video(str(video))\n",
    "        # Run query\n",
    "        result = query_video(frames, prompt, verbose = verbose)\n",
    "        # Save results\n",
    "        results[video_name] = result\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6516db6f-92e3-479d-8670-4769fb081625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing fabio_fashion_3\n",
      "406 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing chamillioneyes_fashion_1\n",
      "386 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $Yes$ (presence of a piano suggests musical entertainment)\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age of person: $26-30$\n",
      "Analyzing fabio_fashion_2\n",
      "436 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_18\n",
      "237 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_19\n",
      "251 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_14\n",
      "219 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_4\n",
      "503 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_17\n",
      "261 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_8\n",
      "443 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_9\n",
      "400 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_12\n",
      "434 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_1\n",
      "224 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_16\n",
      "195 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_11\n",
      "498 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_7\n",
      "320 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_fashion_15\n",
      "240 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_6\n",
      "183 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_13\n",
      "208 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_fashion_10_andpod\n",
      "248 frames read.\n",
      "- Nicotine vaping in this video: $No$\n",
      "- Cannabis vaping in this video: $No$\n",
      "- Fashion in this video: $Yes$\n",
      "- Entertainment in this video: $No$\n",
      "- Technology in this video: $No$\n",
      "- Active lifestyle in this video: $No$\n",
      "- Age range of the person in the video: $22-25$\n",
      "Analyzing fabio_fashion_5\n",
      "461 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing fabio_health_3\n",
      "1730 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $No$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age of person: $26-30$\n",
      "Analyzing drewdirps_health_2\n",
      "1800 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $No$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age of the person: $31-40$\n",
      "Analyzing fabio_health_2_and_pod\n",
      "1802 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age of person: $22-25$\n",
      "Analyzing arabella_health_1\n",
      "1671 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age of person: $22-25$\n",
      "Analyzing chamil_health_vape\n",
      "263 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing chamillioneyes_health_1\n",
      "2127 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing edripps_health_vape\n",
      "247 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $No$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing drewdirps_health_4\n",
      "269 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing drewdirps_health_1\n",
      "1417 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $No$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age of the person: $26-30$\n",
      "Analyzing vapes_aby_health_1_andvape\n",
      "1290 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age of the person: $18-21$\n",
      "Analyzing vapes_aby_health_2_andvape\n",
      "605 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age of person: $18-21$\n",
      "Analyzing alex_health_vape\n",
      "238 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing drew_health_vape\n",
      "273 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing chamillioneyes_health_2\n",
      "770 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing vapes_aby_health_vape\n",
      "237 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing fabio_health_1\n",
      "434 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing drewdirps_health_3\n",
      "1346 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing alex_health_2\n",
      "431 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "\n",
      "Age range of the person:\n",
      "- 26-30: $Yes$\n",
      "Analyzing arabella_health_2\n",
      "2241 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing alex_health_1\n",
      "737 frames read.\n",
      "- Nicotine vaping: $No$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $No$\n",
      "- Active lifestyle: $Yes$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing drewdirps_ecigs_3\n",
      "722 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $No$\n",
      "- Age of person: $26-30$\n",
      "Analyzing chamillioneyes_ecgis_1\n",
      "573 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing drewdirps_ecigs_4\n",
      "374 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $No$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $26-30$\n",
      "Analyzing edripss_ecgis_2\n",
      "557 frames read.\n",
      "- Nicotine vaping: $Yes$\n",
      "- Cannabis vaping: $No$\n",
      "- Fashion: $Yes$\n",
      "- Entertainment: $No$\n",
      "- Technology: $Yes$\n",
      "- Active lifestyle: $No$\n",
      "- Age range of the person: $22-25$\n",
      "Analyzing chamillioneyes_ecigs_2\n",
      "320 frames read.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m, in \u001b[0;36manalyze_videos\u001b[0;34m(videos, prompt, verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m frames \u001b[38;5;241m=\u001b[39m load_video(\u001b[38;5;28mstr\u001b[39m(video))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run query\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     12\u001b[0m results[video_name] \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mquery_video\u001b[0;34m(frames, prompt, frame_sample, resize_pixels, max_tokens, model, temperature, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     { \u001b[38;5;66;03m# Prompt\u001b[39;00m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     },\n\u001b[1;32m     32\u001b[0m ]\n\u001b[1;32m     34\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m     39\u001b[0m }\n\u001b[0;32m---> 41\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/openai/resources/chat/completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/openai/_base_client.py:1233\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1221\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1229\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1230\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1231\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1232\u001b[0m     )\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/openai/_base_client.py:922\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    915\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    921\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/openai/_base_client.py:951\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    948\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 951\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    957\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/ssl.py:1260\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1259\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/.conda/envs/gptwork/lib/python3.9/ssl.py:1135\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results_noprob = analyze_videos(videos, prompt_noprobs, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c8eee6d-3e9c-4f1c-b4ea-612add299e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing fabio_fashion_3\n",
      "406 frames read.\n",
      "- Probability of nicotine vaping: $0%$\n",
      "- Probability of cannabis vaping: $0%$\n",
      "- Probability of fashion: $100%$\n",
      "- Probability of entertainment: $0%$\n",
      "- Probability of technology (excluding vaping): $0%$\n",
      "- Probability of active lifestyle: $0%$\n",
      "- Probability of age range:\n",
      "  - 0-11 years: $0%$\n",
      "  - 12-17 years: $0%$\n",
      "  - 18-21 years: $0%$\n",
      "  - 22-25 years: $0%$\n",
      "  - 26-30 years: $100%$\n",
      "  - 31-40 years: $0%$\n",
      "  - 41-50 years: $0%$\n",
      "  - 51-60 years: $0%$\n",
      "  - Older than 60 years: $0%$\n",
      "Analyzing chamillioneyes_fashion_1\n",
      "386 frames read.\n",
      "- Probability of nicotine vaping: $0%$\n",
      "- Probability of cannabis vaping: $0%$\n",
      "- Probability of fashion: $90%$\n",
      "- Probability of entertainment (e.g., DJ, video games): $10%$\n",
      "- Probability of technology (excluding vaping): $10%$\n",
      "- Probability of active lifestyle (e.g., sport): $10%$\n",
      "- Age probability:\n",
      "  - 0-11 years: $0%$\n",
      "  - 12-17 years: $0%$\n",
      "  - 18-21 years: $0%$\n",
      "  - 22-25 years: $50%$\n",
      "  - 26-30 years: $50%$\n",
      "  - 31-40 years: $0%$\n",
      "  - 41-50 years: $0%$\n",
      "  - 51-60 years: $0%$\n",
      "  - Older than 60 years: $0%$\n",
      "Analyzing fabio_fashion_2\n",
      "436 frames read.\n",
      "- Probability of nicotine vaping in the video: $0%$\n",
      "- Probability of cannabis vaping in the video: $0%$\n",
      "- Probability of fashion in the video: $95%$\n",
      "- Probability of entertainment in the video: $0%$\n",
      "- Probability of technology in the video (excluding vaping): $0%$\n",
      "- Probability of active lifestyle in the video: $10%$\n",
      "- Probability that the person in the video is between the age of 26-30: $60%$\n",
      "Analyzing fabio_fashion_18\n",
      "237 frames read.\n",
      "- Probability of nicotine vaping: $0%$\n",
      "- Probability of cannabis vaping: $0%$\n",
      "- Probability of fashion: $95%$\n",
      "- Probability of entertainment: $0%$\n",
      "- Probability of technology (not including vaping): $0%$\n",
      "- Probability of active lifestyle: $10%$\n",
      "- Probability of age range:\n",
      "  - 0-11 years: $0%$\n",
      "  - 12-17 years: $0%$\n",
      "  - 18-21 years: $10%$\n",
      "  - 22-25 years: $40%$\n",
      "  - 26-30 years: $40%$\n",
      "  - 31-40 years: $10%$\n",
      "  - 41-50 years: $0%$\n",
      "  - 51-60 years: $0%$\n",
      "  - Older than 60 years: $0%$\n",
      "Analyzing fabio_fashion_19\n",
      "251 frames read.\n",
      "- Probability of nicotine vaping in the video: $0%$\n",
      "- Probability of cannabis vaping in the video: $0%$\n",
      "- Probability of fashion in the video: $95%$\n",
      "- Probability of entertainment in the video: $0%$\n",
      "- Probability of technology in the video (excluding vaping): $0%$\n",
      "- Probability of active lifestyle in the video: $10%$\n",
      "- Probability that the person in the video is between the age of 18-21: $30%$\n",
      "- Probability that the person in the video is between the age of 22-25: $50%$\n",
      "- Probability that the person in the video is between the age of 26-30: $20%$\n",
      "CPU times: user 35.3 s, sys: 147 ms, total: 35.4 s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results_probs = analyze_videos(videos[:5], prompt_probs, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fceb4eb-a00b-4eee-b1f4-e5603dacc14f",
   "metadata": {},
   "source": [
    "### Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56872ede-9c79-4b68-b05e-71c79d144f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gptwork]",
   "language": "python",
   "name": "conda-env-.conda-gptwork-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
